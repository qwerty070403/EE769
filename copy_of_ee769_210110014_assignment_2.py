# -*- coding: utf-8 -*-
"""Copy of EE769_210110014_Assignment 2

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v1Cu_KbNvHlCs82UH5HkyJmmryh4tknp

# **QUESTION 3**
"""

from __future__ import print_function, division
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import torch.backends.cudnn as cudnn
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import os
import copy


cudnn.benchmark = True
plt.ion()   # interactive mode

"""We are importing the required libraries here."""

from google.colab import drive
drive.mount('/content/drive')

# Data augmentation and normalization for training
# Just normalization for validation
data_transforms = {
    'train': transforms.Compose([
        transforms.RandomResizedCrop(224),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
    'val': transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ]),
}

data_dir = '/content/drive/MyDrive/hymenoptera_data/hymenoptera_data'
image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
                                          data_transforms[x])
                  for x in ['train', 'val']}
dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,
                                             shuffle=True, num_workers=4)
              for x in ['train', 'val']}
dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}
class_names = image_datasets['train'].classes

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

"""Here we are loading the dataset"""

def imshow(inp, title=None):
    """Display image for Tensor."""
    inp = inp.numpy().transpose((1, 2, 0))
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    inp = std * inp + mean
    inp = np.clip(inp, 0, 1)
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.pause(0.001)  # pause a bit so that plots are updated


# Get a batch of training data
inputs, classes = next(iter(dataloaders['train']))

# Make a grid from batch
out = torchvision.utils.make_grid(inputs)

imshow(out, title=[class_names[x] for x in classes])

"""We are visualizing a few images above"""

# This is a general function to train a model
def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    since = time.time()

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    for epoch in range(num_epochs):
        print(f'Epoch {epoch}/{num_epochs - 1}')
        print('-' * 10)

        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode

            running_loss = 0.0
            running_corrects = 0

            # Iterate over data.
            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()
                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                # statistics
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)
            if phase == 'train':
                scheduler.step()

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]

            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

            # deep copy the model
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())

        print()

    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val Acc: {best_acc:4f}')

    # load best model weights
    model.load_state_dict(best_model_wts)
    return model

"""We are training the model above"""

def visualize_model(model, num_images=6):
    was_training = model.training
    model.eval()
    images_so_far = 0
    fig = plt.figure()

    with torch.no_grad():
        for i, (inputs, labels) in enumerate(dataloaders['val']):
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            for j in range(inputs.size()[0]):
                images_so_far += 1
                ax = plt.subplot(num_images//2, 2, images_so_far)
                ax.axis('off')
                ax.set_title(f'predicted: {class_names[preds[j]]}')
                imshow(inputs.cpu().data[j])

                if images_so_far == num_images:
                    model.train(mode=was_training)
                    return
        model.train(mode=was_training)

"""We are visualizing the model predictions above"""

model_ft = models.resnet18(weights='IMAGENET1K_V1')
num_ftrs = model_ft.fc.in_features
# Here the size of each output sample is set to 2.
# Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.
model_ft.fc = nn.Linear(num_ftrs, 2)

model_ft = model_ft.to(device)

criterion = nn.CrossEntropyLoss()

# Observe that all parameters are being optimized
optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)

# Decay LR by a factor of 0.1 every 7 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)

"""We are finetuning the ConvNet above"""

model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,
                       num_epochs=25)

"""We are training and evaluating above"""

visualize_model(model_ft)

"""We are visualizing the predictions above"""

from PIL import Image
from torch.autograd import Variable

# Reference Used : https://becominghuman.ai/extract-a-feature-vector-for-any-image-with-pytorch-9717561d1d4c

# ResNet-18 expects images to be at least 224x224, as well as normalized with a specific mean and standard deviation.
# Hence, we will first define some PyTorch transforms:

scaler = transforms.Resize((224, 224))
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
to_tensor = transforms.ToTensor()

# Use the model object to select the desired layer
layer = model_ft._modules.get('avgpool')

# Additional reference used to get around a bug in the code : https://stackoverflow.com/questions/61606416/runtimeerror-output-with-shape-512-doesnt-match-the-broadcast-shape-1-512

def get_vector(inputs):
    # Create a PyTorch Variable with the transformed image
    t_img = Variable(inputs.unsqueeze(0))
    # Create a vector of zeros that will hold our feature vector
    my_embedding = torch.zeros(512) # The 'avgpool' layer has an output size of 512
    # Define an inner function that will copy the output of a layer
    def copy_data(m, i, o):
        my_embedding.copy_(o.data.reshape(o.data.size(1)))
    # Attach that function to our selected layer
    h = layer.register_forward_hook(copy_data)
    # Run the model on our transformed image
    model_ft(t_img)
    # Detach our copy function from the layer
    h.remove()
    # Return the feature vector
    return my_embedding

features = np.zeros((512,1))
labels = np.zeros((1,1))
for img in image_datasets['train']: # img[0] is a PyTorch tensor whereas img[1] refers to the class : ants/bees
    img_tensor = img[0].to(device)
    img_feature = get_vector(img_tensor)
    img_feature = img_feature.numpy()
    img_feature = img_feature.reshape(len(img_feature),1)
    features = np.concatenate((features, img_feature), axis = 1)
    img_label = img[1]
    img_label = np.array(img_label)
    img_label = img_label.reshape(1,1)
    labels = np.concatenate((labels, img_label), axis = 1)
features = features.T
labels = labels.T

x = features[1:,:]
y = labels[1:,:]

"""Write a function that outputs ResNet18 features for a given input image. Extract features for training images (in image_datasets['train']). You should get an Nx512 dimensional array."""

from sklearn import svm
!pip install scikit-learn
from sklearn.model_selection import GridSearchCV

hyper = {'C' : [0.001,0.01,0.1,1,10], 'degree' : [2,3,5,7]} # Regularization and kernel width are the only hyperparameters that are to be tuned
svc = svm.SVC(kernel='rbf', probability = True)
scoring = ['balanced_accuracy', 'f1', 'roc_auc']

for i in scoring:
  clf = GridSearchCV(estimator = svc, param_grid = hyper, scoring = i) # since cv = None -> We wish to use the default 5-fold cross validation splitting strategy
  clf.fit(np.array(x),np.squeeze(y))
  print('Best hyperparameter : ', clf.best_params_) # Print best parameter after tuning
  print('Best ' + i + ' : ' + str(clf.best_score_))

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
import numpy as np

rf = RandomForestClassifier()
param = {'n_estimators': [50, 100, 200, 300, 400], 'max_depth': [2, 4, 6, 8, 10]}
scoring = ['balanced_accuracy', 'f1', 'roc_auc']

for i in scoring:
    clf = GridSearchCV(estimator=rf, param_grid=param, scoring=i, n_jobs=-1)
    clf.fit(np.array(x), np.squeeze(y))
    print('Best hyperparameter : ', clf.best_params_)  # Print best parameter after tuning
    print('Best ' + i + ' : ' + str(clf.best_score_))

features_test = np.zeros((512,1))
labels_test = np.zeros((1,1))
for img in image_datasets['val']: # Due to the unavailability of the testing dataset, I am hence evaluating the performance of my model on the validation dataset
    img_tensor = img[0].to(device)
    img_feature = get_vector(img_tensor)
    img_feature = img_feature.numpy()
    img_feature = img_feature.reshape(len(img_feature),1)
    features_test = np.concatenate((features_test, img_feature), axis = 1)
    img_label = img[1]
    img_label = np.array(img_label)
    img_label = img_label.reshape(1,1)
    labels_test = np.concatenate((labels_test, img_label), axis = 1)
features_test = features_test.T
labels_test = labels_test.T
x_test = features_test[1:,:]
y_test = labels_test[1:,:]

from sklearn.metrics import balanced_accuracy_score
from sklearn.metrics import f1_score

# Best Model -> SVM with C=10 and degree=2
svc = svm.SVC(kernel='rbf', probability = True, C='10',degree='2')

clf.fit(np.array(x),np.squeeze(y))

# Predicted target variables for binary class
y_pred = clf.predict(x_test)

# Checking accuracy of model on test data
f1 = f1_score(y_pred, y_test)
print('f1: %.3f' % (f1*100))

balanced_accuracy = balanced_accuracy_score(y_pred, y_test)
print('balanced_accuracy: %.3f' % (balanced_accuracy*100))

"""Clearly as per our data, SVM is the model we would like to use.

# **QUESTION 1**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sys
plt.style.use('ggplot')
# above we are importing all libraries that will be useful
# Importing functions from sklearn library now
from sklearn import preprocessing
from sklearn.model_selection import train_test_split

# Importing the dataset..thanks to my good friend Vedant Yadav(210110116) who told me about a delimiter
d_red = pd.read_csv('winequality-red.csv', delimiter=';')
d_white = pd.read_csv('winequality-white.csv', delimiter=';')

"""Above we have finished the a part of question 1"""

# View the first few rows of the DataFrame
print(d_red.head())

# Get summary statistics of the data
print(d_red.describe())

# Check for missing values
print(d_red.isnull().sum())

# Check data types
print(d_red.dtypes)

# View the first few rows of the DataFrame
print(d_white.head())

# Get summary statistics of the data
print(d_white.describe())

# Check for missing values
print(d_white.isnull().sum())

# Checking data types
print(d_white.dtypes)
# Check the parameters now
print(d_red.columns)
print(d_white.columns)

"""We clearly see that we have no null values in our both datasets of red and white wine. We have also listed the datatypes of the variables and taken a brief summary...thanks to ChatGPT which adviced me to visualize data in the above manner"""

d_red.duplicated()# to check for repeated rows/values in our dataset and eliminate them
d_white.duplicated()

d_red = d_red.drop_duplicates().copy()
d_white = d_white.drop_duplicates().copy()
print(d_red.shape)# to check for number of rows and columns in our dataset which are unique and not repeated
print(d_white.shape)

"""Here, we have pre-processed our data and hence we can move onto data visualization now"""

# Plot histograms for numerical columns
d_red.hist(figsize=(10, 8))
plt.tight_layout()
plt.show() # so the red histograms represent the columns of our red wine
d_white.hist(figsize=(10, 8), color='b')
plt.tight_layout()
plt.show()# the blue histograms represent columns of the white wine

# Plot box plots for numerical columns
d_red.boxplot(figsize=(10, 8))
plt.title('Box Plot for Red Wine')
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability..thanks to ChatGPT
plt.show()
d_white.boxplot(figsize=(10, 8))
plt.title('Box Plot for White Wine')
plt.xticks(rotation=45)  # Rotate x-axis labels for better readability..thanks to ChatGPT
plt.show()

"""So far. the idea we are getting from our Box Plot tells that all the variables are needed for predicting the value of our wine quality. We must get some further validation."""

from pandas.plotting  import scatter_matrix # this was again recommended to me by my friend Vedant Yadav(210110116)
scatter_matrix(d_red, alpha=0.2, figsize=(26,26), diagonal='kde', color='r')
scatter_matrix(d_white, alpha=0.2, figsize=(26,26), diagonal='kde', color='b')

"""We have made the scatterplots now, these plots clearly tell us the quality depends on all the variables, hence we can not really drop any variable in our prediction. We must now find the correlations for final verification."""

# Assuming d_red is your DataFrame
plt.figure(figsize=(10, 8))
sns.heatmap(d_red.corr(), annot=True, cmap='coolwarm')
plt.title('Heatmap of d_red Dataset')
plt.show()
# Assuming d_white is your DataFrame
plt.figure(figsize=(10, 8))
sns.heatmap(d_white.corr(), annot=True, cmap='coolwarm')
plt.title('Heatmap of d_white Dataset')
plt.show()

"""This confirms are our earlier findings that none of the 11 variables can be dropped in predicting the quality. We require all 11, clearly shown from our correlation values.

The above concludes Question 1b
"""

from sklearn.model_selection import train_test_split
from sklearn import preprocessing
train_red, test_red = train_test_split(d_red, test_size=0.2, random_state=42)
scaler = preprocessing.StandardScaler() # for data normalization
cols_data = d_red.columns.drop('quality').values  # columns to be used for training
scaler.fit(train_red[cols_data])

train_red_X = pd.DataFrame(scaler.transform(train_red[cols_data]))
train_red_Y = pd.DataFrame(train_red['quality'])
test_red_X = pd.DataFrame(scaler.transform(test_red[cols_data]))
test_red_Y = pd.DataFrame(test_red['quality'])
# doing this for red wine data
train_white, test_white = train_test_split(d_white, test_size=0.2, random_state=42)
scaler = preprocessing.StandardScaler() # for data normalization
cols_data = d_white.columns.drop('quality').values  # columns to be used for training
scaler.fit(train_white[cols_data])

train_white_X = pd.DataFrame(scaler.transform(train_white[cols_data]))
train_white_Y = pd.DataFrame(train_white['quality'])
test_white_X = pd.DataFrame(scaler.transform(test_white[cols_data]))
test_white_Y = pd.DataFrame(test_white['quality'])
# now doing this for white wine data







# Preprocessing data
# Normalise the data set and make it zero mean and unit variance

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error
# Assuming train_data_X, train_data_Y, test_data_X, test_data_Y are defined
# Define the hyperparameters grid
param_grid = {
    'n_estimators': [10,50, 100, 150, 200],
    'max_depth': [None,3,6, 10, 20, 30]  # Varying the number of trees and the depth of the trees
}
# Instantiate the RandomForestRegressor
rf_regressor = RandomForestRegressor(random_state=42)
# Instantiate the grid search model
grid_search = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')
# Fit the grid search to the training data
grid_search.fit(train_red_X, train_red_Y.values.ravel())
# Get the best hyperparameters
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Get the best model
best_rf_regressor_red = grid_search.best_estimator_

# Predict on the test set using the best model
y_pred_test = best_rf_regressor_red.predict(test_red_X)

# Evaluate the performance of the best model
mse_test = mean_squared_error(test_red_Y, y_pred_test)
print("Mean Squared Error on Test Set with Best Model:", mse_test)

"""We have applied random forest regressor to red wine and clearly validation and MSE do not differ by a large value i.e they are quite near to each other. Hence, this could be one of the valid models.Also, we have varied 2 hyperparameters i.e n_estimators and max depth and found the best value of the same. ChatGPT really helped me with all the syntaxes as I was finding it very difficult to implement the same."""

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error

# Assuming train_data_X, train_data_Y, test_data_X, test_data_Y are defined

# Define the hyperparameters grid
param_grid = {
    'n_estimators': [10,50, 100, 150, 200],
    'max_depth': [None,3,6, 10, 20, 30]  # Varying the number of trees and the depth of the trees
}

# Instantiate the RandomForestRegressor
rf_regressor = RandomForestRegressor(random_state=42)

# Instantiate the grid search model
grid_search = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')

# Fit the grid search to the training data
grid_search.fit(train_white_X, train_white_Y.values.ravel())

# Get the best hyperparameters
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Get the best model
best_rf_regressor_white = grid_search.best_estimator_

# Predict on the test set using the best model
y_pred_test = best_rf_regressor_white.predict(test_white_X)

# Evaluate the performance of the best model
mse_test = mean_squared_error(test_white_Y, y_pred_test)
print("Mean Squared Error on Test Set with Best Model:", mse_test)

"""We have applied random forest classification to white wine and clearly validation and test accuracy do not differ by a large value i.e they are quite near to each other. Hence, this could be one of the valid models.Also, we have varied 2 hyperparameters i.e n_estimators and max depth and found the best value of the same. ChatGPT really helped me with all the syntaxes as I was finding it very difficult to implement the same."""

from sklearn.svm import SVR
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error

# Assuming train_data_X, train_data_Y, test_data_X, test_data_Y are defined

# Define the hyperparameters grid
param_grid = {
    'C': [0.1, 1, 10, 100],  # Regularization parameter
    'gamma': ['scale', 'auto']  # Kernel coefficient
}

# Instantiate the SVR with RBF kernel
svr_regressor = SVR(kernel='rbf')

# Instantiate the grid search model
grid_search = GridSearchCV(estimator=svr_regressor, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')

# Fit the grid search to the training data
grid_search.fit(train_red_X, train_red_Y.values.ravel())

# Get the best hyperparameters
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Get the best model
best_svr_regressor_red = grid_search.best_estimator_

# Predict on the test set using the best model
y_pred_test = best_svr_regressor_red.predict(test_red_X)

# Evaluate the performance of the best model
mse_test = mean_squared_error(test_red_Y, y_pred_test)
print("Mean Squared Error on Test Set with Best Model:", mse_test)

"""For red wine we clearly see that validation MSE and Test MSE are quite close to one another and hence clearly this model could also be used. We varied 3 hyperparameters and found the best ones for us. ChatGPT greatly helped me with the libraries and coding part with blocks and syntaxes."""

from sklearn.svm import SVR
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error

# Assuming train_data_X, train_data_Y, test_data_X, test_data_Y are defined

# Define the hyperparameters grid
param_grid = {
    'C': [0.1, 1, 10, 100],  # Regularization parameter
    'gamma': ['scale', 'auto']  # Kernel coefficient
}

# Instantiate the SVR with RBF kernel
svr_regressor = SVR(kernel='rbf')

# Instantiate the grid search model
grid_search = GridSearchCV(estimator=svr_regressor, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')

# Fit the grid search to the training data
grid_search.fit(train_white_X, train_white_Y.values.ravel())

# Get the best hyperparameters
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Get the best model
best_svr_regressor_white = grid_search.best_estimator_

# Predict on the test set using the best model
y_pred_test = best_svr_regressor_white.predict(test_white_X)

# Evaluate the performance of the best model
mse_test = mean_squared_error(test_white_Y, y_pred_test)
print("Mean Squared Error on Test Set with Best Model:", mse_test)

"""For white wine we clearly see that validation MSE and Test MSE are quite close to one another and hence clearly this model could also be used. We varied 3 hyperparameters and found the best ones for us. ChatGPT greatly helped me with the libraries and coding part with blocks and syntaxes.

# **With this we conclude Question 1c)**
"""

# Get feature names and their importances
feature_names = train_red.columns.drop('quality')
feature_importances = best_rf_regressor_red.feature_importances_

# Create a DataFrame to store feature names and importances
feature_importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})

# Sort features by importance value
feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)

# Print feature importances
print("Random Forest Feature Importances:")
print(feature_importances_df)

# Get feature names and their importances
feature_names = train_red.columns.drop('quality')
feature_importances = best_rf_regressor_white.feature_importances_

# Create a DataFrame to store feature names and importances
feature_importances_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})

# Sort features by importance value
feature_importances_df = feature_importances_df.sort_values(by='Importance', ascending=False)

# Print feature importances
print("Random Forest Feature Importances:")
print(feature_importances_df)

# Get support vectors' coefficients
dual_coefficients = best_svr_regressor_red.support_vectors_

# Create a DataFrame to store support vectors' coefficients
dual_coefficients_df = pd.DataFrame(dual_coefficients, columns=feature_names)

# Print support vectors' coefficients
print("SVR (RBF Kernel) Support Vectors' Coefficients:")
print(dual_coefficients_df)
# Assuming dual_coefficients is obtained from best_svr_regressor_red.support_vectors_

# Take the absolute values of support vectors' coefficients
abs_dual_coefficients = np.abs(dual_coefficients)

# Calculate the average importance of each feature
feature_importance = abs_dual_coefficients.mean(axis=0)

# Create a DataFrame to store feature importance scores
feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})

# Sort features by importance
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Print feature importance scores
print("Feature Importance Scores:")
print(feature_importance_df)

# Visualization: Bar plot of feature importance scores
plt.figure(figsize=(10, 6))
plt.bar(feature_importance_df['Feature'], feature_importance_df['Importance'])
plt.xlabel('Feature')
plt.ylabel('Importance')
plt.title('Feature Importance Scores')
plt.xticks(rotation=90)
plt.show()

# Get support vectors' coefficients
dual_coefficients1 = best_svr_regressor_white.support_vectors_

# Create a DataFrame to store support vectors' coefficients
dual_coefficients_df = pd.DataFrame(dual_coefficients1, columns=feature_names)

# Print support vectors' coefficients
print("SVR (RBF Kernel) Support Vectors' Coefficients:")
print(dual_coefficients_df)
# Assuming dual_coefficients is obtained from best_svr_regressor_red.support_vectors_

# Take the absolute values of support vectors' coefficients
abs_dual_coefficients1 = np.abs(dual_coefficients1)

# Calculate the average importance of each feature
feature_importance = abs_dual_coefficients1.mean(axis=0)

# Create a DataFrame to store feature importance scores
feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importance})

# Sort features by importance
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Print feature importance scores
print("Feature Importance Scores:")
print(feature_importance_df)

# Visualization: Bar plot of feature importance scores
plt.figure(figsize=(10, 6))
plt.bar(feature_importance_df['Feature'], feature_importance_df['Importance'])
plt.xlabel('Feature')
plt.ylabel('Importance')
plt.title('Feature Importance Scores')
plt.xticks(rotation=90)
plt.show()

"""# **With this, we conclude our Question 1d**"""

y_hat_red = best_rf_regressor_white.predict(test_red_X)
print(f"Mean Squared Error of White's model tested on red data using Random Forest: {mean_squared_error(y_hat_red, test_red_Y)}")

y_hat_red = best_svr_regressor_white.predict(test_red_X)
print(f"Mean Squared Error of White's model tested on red data using SVM: {mean_squared_error(y_hat_red, test_red_Y)}")

"""MSE clearly low for SV regression, so it is slightly better to use than Random Forest regressor. The MSE are low for both( around 0.5) so whites model can be used on red data"""

y_hat_white = best_rf_regressor_red.predict(test_white_X)
print(f"Mean Squared Error of Red's model tested on white data using Random Forest: {mean_squared_error(y_hat_white, test_white_Y)}")

y_hat_white = best_svr_regressor_red.predict(test_white_X)
print(f"Mean Squared Error of Red's model tested on white data using SVM: {mean_squared_error(y_hat_white, test_white_Y)}")

"""MSE here are on the higher side compared to what we are getting. It might not be feasible to use reds model on white wine data.

# **Above we have discussed question 1e**

# **Now we are starting with Question 2**
"""

# Importing all necessary questions as shown in Question 1
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
pd.set_option('display.max_rows', 100)
plt.style.use('ggplot')

data = pd.read_csv('Data_Cortex_Nuclear.csv')

# View the first few rows of the DataFrame
print(data.head())
# Get summary statistics of the data
print(data.describe())
# Check data types
print(data.dtypes)

# Print the column names of your DataFrame
print("Column Names:", data.columns)
data['Genotype'] = data['Genotype'].replace('Control', 0)
data['Genotype'] = data['Genotype'].replace('Ts65Dn', 1)
data['Genotype'] = data['Genotype'].astype(int)

"""We are encoding the 2 possible genotypes by 0 and 1. This was recommended to me by my good friend Vedant Yadav(210110116) who also helped me with the layout."""

# Assuming data is your DataFrame
plt.figure(figsize=(200, 160))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm')
plt.title('Heatmap of data_cortex_nuclear Dataset')
plt.show()

data = data.drop(['MouseID', 'Treatment', 'Behavior', 'class'], axis = 1).copy()

# Extract pairs of variables with correlation greater than 0.9
high_corr_pairs = [(data.columns[i], data.columns[j], data.corr().iloc[i, j])
                   for i in range(len(data.columns))
                   for j in range(i+1, len(data.columns))
                   if abs(data.corr().iloc[i, j]) > 0.9]
# Print pairs of variables with correlation greater than 0.9
for pair in high_corr_pairs:
    print(f"Variables '{pair[0]}' and '{pair[1]}' have correlation {pair[2]}")

data = data.drop(['ITSN1_N', 'pERK_N', 'BRAF_N', 'Bcatenin_N','pNR1_N','pS6_N'], axis = 1).copy()

"""Variables 'ARC_N' and 'pS6_N' have correlation 1.0, so we can remove one of the two in order to prevent future mismatches. We can also see that both of them have no null values( thanks to Vedant Yadav for pointing that out to me). So one of the columns can easily be removed.

so we have dropped the columns that we will not be requiring for our prediction of the genotype.
"""

print("Column Names:", data.columns)

"""This has been done to replace the 2 types of genotype by 0 and 1"""

# Make list of columns which have missing values
cols_with_null = []
for cols in data.columns:
  if (data[cols].isna().sum() > 0):
    cols_with_null.append(cols)
for cols in cols_with_null:
  data[cols] = pd.to_numeric(data[cols], errors='coerce')

# Setup scikit imputer
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import IterativeImputer
imp = IterativeImputer(max_iter = 10, random_state = 0)
data_imputed = imp.fit_transform(data)
data = pd.DataFrame(data_imputed, columns = data.columns).copy()
data.isna().sum()

"""Again, credits to ChatGPT here for giving me a layout for finding columns that have null values so that we can impute 0 in those places.

Thanks to Amit Sethi sir for the handout which gave a very basic way to import iterative imputer from the sklearn.experimental library. Then when I printed the null values in each column, I get 0 null values in each column.

# With this, we conclude **Question 2b**
"""

from sklearn.model_selection import train_test_split
from sklearn import preprocessing
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)
scaler = preprocessing.StandardScaler() # for data normalization
cols_data = data.columns.drop('Genotype').values  # columns to be used for training
scaler.fit(train_data[cols_data])
train_data_X = pd.DataFrame(scaler.transform(train_data[cols_data]))
train_data_Y = pd.DataFrame(train_data['Genotype'])
test_data_X = pd.DataFrame(scaler.transform(test_data[cols_data]))
test_data_Y = pd.DataFrame(test_data['Genotype'])

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score

import pandas as pd

# Assuming train_data_X, train_data_Y, test_data_X, test_data_Y are defined

# Define the hyperparameters grid
param_grid = {
    'n_estimators': [50, 100, 150, 200],'max_depth': [None, 10, 20, 30]  # Varying the number of trees and the depth of the trees
}

# Instantiate the RandomForestClassifier
rf_classifier = RandomForestClassifier(random_state=42)

# Instantiate the grid search model
grid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')

# Fit the grid search to the training data
grid_search.fit(train_data_X, train_data_Y.values.ravel())

# Get the best hyperparameters
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

"""We now get our best hyperparameters to now apply it on our Random Classifier Model and find our best model accuracy."""

# Re-train the model using the best hyperparameters
best_rf_classifier = RandomForestClassifier(n_estimators=200, random_state=42)
best_rf_classifier.fit(train_data_X, train_data_Y.values.ravel())
# Predicting on the test set using the best model
y_pred_best = best_rf_classifier.predict(test_data_X)

# Calculating accuracy of the best model
accuracy_best = accuracy_score(test_data_Y, y_pred_best)
print("Best Model Accuracy:", accuracy_best)

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)
scaler = preprocessing.StandardScaler() # for data normalization
cols_data = data.columns.drop('Genotype').values  # columns to be used for training
scaler.fit(train_data[cols_data])
train_data_X = pd.DataFrame(scaler.transform(train_data[cols_data]))
train_data_Y = pd.DataFrame(train_data['Genotype'])
test_data_X = pd.DataFrame(scaler.transform(test_data[cols_data]))
test_data_Y = pd.DataFrame(test_data['Genotype'])


# Define the SVC classifier with RBF kernel
svc_classifier = SVC(kernel='rbf')  # Default hyperparameters..as specified in the question

# Define the hyperparameters grid
param_grid = {
    'C': [0.1, 1, 10, 100],  # Regularization parameter..our first hyperparameter
    'gamma': [0.1, 1, 10, 100]  # Kernel coefficient our second hyperparameter
}

# Instantiate the grid search model..recommended to me by ChatGPT
grid_search = GridSearchCV(estimator=svc_classifier, param_grid=param_grid, cv=5, scoring='accuracy')

# Fit the grid search to the data
grid_search.fit(train_data_X, train_data_Y.values.ravel())# this was recommended by google collab itself..using ravel

# Get the best hyperparameters
best_params = grid_search.best_params_
print("Best Hyperparameters:", best_params)

# Re-train the model using the best hyperparameters
best_svc_classifier = SVC(kernel='rbf', C=10,gamma=0.1)
best_svc_classifier.fit(train_data_X, train_data_Y)

# Predicting on the test set using the best model
y_pred_best = best_svc_classifier.predict(test_data_X)

# Calculating accuracy of the best model
accuracy_best = accuracy_score(test_data_Y, y_pred_best)
print("Best Model Accuracy:", accuracy_best)

from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import RFECV
from sklearn.metrics import accuracy_score
import pandas as pd

# Split the data into train and test sets
train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)

# Standardize the data
scaler = preprocessing.StandardScaler()
cols_data = data.columns.drop('Genotype').values
scaler.fit(train_data[cols_data])
train_data_X = pd.DataFrame(scaler.transform(train_data[cols_data]))
train_data_Y = pd.DataFrame(train_data['Genotype'])
test_data_X = pd.DataFrame(scaler.transform(test_data[cols_data]))
test_data_Y = pd.DataFrame(test_data['Genotype'])

# Initialize the RandomForestClassifier
rf_classifier = RandomForestClassifier(n_estimators=200, random_state=42)

# Initialize the RFECV object with the chosen model and scoring metric
rfecv = RFECV(estimator=rf_classifier, cv=5, scoring='accuracy')

# Fit the RFECV object to the training data
rfecv.fit(train_data_X, train_data_Y.values.ravel())

# Access the selected features
selected_features = rfecv.support_

# Transform the data using the selected features
train_data_X_selected = train_data_X.iloc[:, selected_features]
test_data_X_selected = test_data_X.iloc[:, selected_features]

# Retrain the model on the transformed data
rf_classifier.fit(train_data_X_selected, train_data_Y.values.ravel())

# Predict on the test set
y_pred_test = rf_classifier.predict(test_data_X_selected)

# Evaluate the performance of the model with selected features on the test set
accuracy_test = accuracy_score(test_data_Y, y_pred_test)
print("Accuracy on Test Set with Selected Features:", accuracy_test)

# Fit the RFECV object to the training data
rfecv.fit(train_data_X, train_data_Y.values.ravel())

# Access the selected features
selected_features = train_data_X.columns[rfecv.support_]

print("Selected Features:",rfecv.support_)
print(selected_features)

from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.decomposition import PCA
from sklearn.metrics import accuracy_score



# Apply PCA for dimensionality reduction
pca = PCA(n_components=10)  # Adjust the number of components as needed
X_train_pca = pca.fit_transform(train_data_X)
X_test_pca = pca.transform(test_data_X)

# Initialize the SVC model with RBF kernel
svm_classifier = SVC(kernel='rbf', C=10, gamma=0.1)

# Fit the SVC model on the reduced dimensionality data
svm_classifier.fit(X_train_pca, train_data_Y.values.ravel())

# Predict on the test set
y_pred_test = svm_classifier.predict(X_test_pca)

# Evaluate the performance of the model
accuracy_test = accuracy_score(test_data_Y, y_pred_test)
print("Accuracy on Test Set with PCA:", accuracy_test)

# Get the indices of the selected principal components
selected_components = pca.components_

# Print the selected principal components
print("Selected Principal Components:")
for component_idx, component in enumerate(selected_components):
    print(f"Component {component_idx + 1}: {component}")